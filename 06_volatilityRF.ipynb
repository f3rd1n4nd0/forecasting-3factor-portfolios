{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Random Forest to Forecast Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape: (414, 6)\n",
      "SMALL LoBM series shape: (414,)\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\GIORDANO\\Desktop\\financial-time-series-forecasting\\data\\Developed_6_Portfolios_ME_BE-ME_cleaned_decimals.csv\"\n",
    "df = pd.read_csv(file_path, parse_dates=True, index_col='date')\n",
    "print(\"Full dataset shape:\", df.shape)\n",
    "\n",
    "# Extract the SMALL LoBM returns\n",
    "returns_small = df[\"SMALL LoBM\"].dropna()\n",
    "print(\"SMALL LoBM series shape:\", returns_small.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target sample:\n",
      "            returns  vol_target\n",
      "date                           \n",
      "1990-10-01   0.0520    0.080844\n",
      "1990-11-01  -0.0312    0.096786\n",
      "1990-12-01   0.0124    0.080120\n",
      "1991-01-01   0.0095    0.041616\n",
      "1991-02-01   0.1274    0.024378\n"
     ]
    }
   ],
   "source": [
    "# 2. Define Target: Realized Volatility\n",
    "# -------------------------------\n",
    "# For each date t, the target is the volatility computed from returns at t-3 to t-1 (using past data only)\n",
    "df_vol = pd.DataFrame({'returns': returns_small})\n",
    "# Shift by 1 so that at time t, volatility is computed using t-1, t-2, t-3\n",
    "df_vol['vol_target'] = df_vol['returns'].shift(1).rolling(window=3).std()\n",
    "df_vol.dropna(inplace=True)\n",
    "print(\"Target sample:\")\n",
    "print(df_vol.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature DataFrame sample:\n",
      "            returns  lag_sq_1  lag_sq_2  lag_sq_3  roll_std_6\n",
      "date                                                         \n",
      "1991-01-01   0.0095  0.000154  0.000973  0.002704    0.072221\n",
      "1991-02-01   0.1274  0.000090  0.000154  0.000973    0.070270\n",
      "1991-03-01   0.0142  0.016231  0.000090  0.000154    0.079020\n",
      "1991-04-01   0.0064  0.000202  0.016231  0.000090    0.054208\n",
      "1991-05-01   0.0053  0.000041  0.000202  0.016231    0.053823\n"
     ]
    }
   ],
   "source": [
    "# 3. Feature Engineering for Volatility Forecasting (Avoiding Leakage)\n",
    "# -------------------------------\n",
    "def create_vol_features(series):\n",
    "    \"\"\"\n",
    "    Generates features for volatility forecasting.\n",
    "    Features include:\n",
    "    - Lagged squared returns (lags 1, 2, 3)\n",
    "    - Rolling standard deviation over a 6-month window, shifted by 1.\n",
    "    \"\"\"\n",
    "    df_feat = pd.DataFrame({'returns': series})\n",
    "    df_feat['lag_sq_1'] = (df_feat['returns'] ** 2).shift(1)\n",
    "    df_feat['lag_sq_2'] = (df_feat['returns'] ** 2).shift(2)\n",
    "    df_feat['lag_sq_3'] = (df_feat['returns'] ** 2).shift(3)\n",
    "    df_feat['roll_std_6'] = df_feat['returns'].rolling(window=6).std().shift(1)\n",
    "    df_feat.dropna(inplace=True)\n",
    "    return df_feat\n",
    "\n",
    "features_df = create_vol_features(returns_small)\n",
    "print(\"Feature DataFrame sample:\")\n",
    "print(features_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged model DataFrame shape: (408, 6)\n",
      "            vol_target  returns  lag_sq_1  lag_sq_2  lag_sq_3  roll_std_6\n",
      "date                                                                     \n",
      "1991-01-01    0.041616   0.0095  0.000154  0.000973  0.002704    0.072221\n",
      "1991-02-01    0.024378   0.1274  0.000090  0.000154  0.000973    0.070270\n",
      "1991-03-01    0.067248   0.0142  0.016231  0.000090  0.000154    0.079020\n",
      "1991-04-01    0.066754   0.0064  0.000202  0.016231  0.000090    0.054208\n",
      "1991-05-01    0.067720   0.0053  0.000041  0.000202  0.016231    0.053823\n",
      "Correlation with target:\n",
      "vol_target    1.000000\n",
      "roll_std_6    0.727630\n",
      "lag_sq_3      0.586136\n",
      "lag_sq_2      0.516634\n",
      "lag_sq_1      0.487525\n",
      "returns      -0.043839\n",
      "Name: vol_target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 4. Merge Features and Target (Ensure No Leakage)\n",
    "# -------------------------------\n",
    "df_model = pd.merge(df_vol[['vol_target']], features_df, left_index=True, right_index=True, how='inner')\n",
    "df_model.dropna(inplace=True)\n",
    "print(\"Merged model DataFrame shape:\", df_model.shape)\n",
    "print(df_model.head())\n",
    "\n",
    "# Check correlations between features and target:\n",
    "corr_matrix = df_model.corr()\n",
    "print(\"Correlation with target:\")\n",
    "print(corr_matrix['vol_target'].sort_values(ascending=False))\n",
    "# A perfect (or near-perfect) correlation would indicate leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training period: 1991-01-01 00:00:00 to 2015-12-01 00:00:00\n",
      "Testing period: 2016-01-01 00:00:00 to 2024-12-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# 5. Train/Test Split (Time-Series Aware)\n",
    "\n",
    "train_df = df_model.loc[:'2015-12-31']\n",
    "test_df = df_model.loc['2016-01-01':]\n",
    "print(\"Training period:\", train_df.index.min(), \"to\", train_df.index.max())\n",
    "print(\"Testing period:\", test_df.index.min(), \"to\", test_df.index.max())\n",
    "\n",
    "X_train = train_df.drop(columns=['vol_target'])\n",
    "y_train = train_df['vol_target']\n",
    "X_test = test_df.drop(columns=['vol_target'])\n",
    "y_test = test_df['vol_target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest params: {'n_estimators': 200, 'min_samples_split': 2, 'max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "# 6. Random Forest Model Training with TimeSeriesSplit CV\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=20,\n",
    "                               scoring='neg_mean_squared_error', cv=tscv, n_jobs=-1, random_state=42)\n",
    "rf_search.fit(X_train, y_train)\n",
    "print(\"Best Random Forest params:\", rf_search.best_params_)\n",
    "\n",
    "best_rf = rf_search.best_estimator_\n",
    "pred_rf = best_rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Volatility Forecast Performance:\n",
      "MAE: 0.0114\n",
      "RMSE: 0.0164\n",
      "\n",
      "GARCH Benchmark Volatility Forecast Performance:\n",
      "MAE: 0.0323, RMSE: 0.0378\n"
     ]
    }
   ],
   "source": [
    "# 7. Evaluate Model Performance\n",
    "mae_rf = mean_absolute_error(y_test, pred_rf)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, pred_rf))\n",
    "print(f\"Random Forest Volatility Forecast Performance:\\nMAE: {mae_rf:.4f}\\nRMSE: {rmse_rf:.4f}\")\n",
    "\n",
    "# Benchmark from GARCH (provided earlier):\n",
    "garch_mae = 0.0323\n",
    "garch_rmse = 0.0378\n",
    "print(\"\\nGARCH Benchmark Volatility Forecast Performance:\")\n",
    "print(f\"MAE: {garch_mae:.4f}, RMSE: {garch_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Plot Forecasted vs. Realized Volatility\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(y_test.index, y_test, label='Realized Volatility', color='blue')\n",
    "plt.plot(y_test.index, pred_rf, label='RF Forecasted Volatility', color='red', linestyle='--')\n",
    "plt.title(\"Random Forest Volatility Forecast for SMALL LoBM\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Volatility\")\n",
    "plt.legend()\n",
    "plt.savefig(\"plots/rf_vol_forecast.png\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
