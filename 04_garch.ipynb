{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GARCH Modeling for Volatility Forecasting (SMALL LoBM)\n",
    "\n",
    "_In this notebook, we focus on forecasting volatility rather than returns. We use the GARCH(1,1) model, a widely adopted approach for capturing time-varying volatility in financial time series._\n",
    "\n",
    "**Key Steps:**\n",
    " 1. Load the dataset for the SMALL LoBM portfolio.\n",
    " 2. Split the data into training and testing sets (similar date split as before).\n",
    " 3. Specify and fit a GARCH(1,1) model using the `arch` library.\n",
    " 4. Generate volatility forecasts for the test period.\n",
    " 5. Compare predicted volatility to realized volatility (e.g., squared returns) and compute performance metrics such as MAE or RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from arch import arch_model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-dark-palette')\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Shape: (414, 6)\n",
      "            SMALL LoBM  ME1 BM2  SMALL HiBM  BIG LoBM  ME2 BM2  BIG HiBM\n",
      "date                                                                    \n",
      "1990-07-01      0.0243   0.0191      0.0097    0.0064   0.0168    0.0139\n",
      "1990-08-01     -0.1222  -0.1149     -0.1055   -0.0951  -0.1000   -0.1021\n",
      "1990-09-01     -0.1082  -0.1001     -0.0938   -0.1177  -0.1079   -0.1160\n",
      "1990-10-01      0.0520   0.0350      0.0054    0.1304   0.1020    0.0874\n",
      "1990-11-01     -0.0312  -0.0105     -0.0086   -0.0345  -0.0242   -0.0345\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"\\data\\Developed_6_Portfolios_ME_BE-ME_cleaned_decimals.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df_garch = pd.read_csv(file_path, parse_dates=True, index_col='date')\n",
    "print(\"Dataset loaded. Shape:\", df_garch.shape)\n",
    "print(df_garch.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_name = \"SMALL LoBM\"\n",
    "returns = df_garch[portfolio_name].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using SMALL LoBM for GARCH modeling. Data shape: (414,)\n",
      "date\n",
      "1990-07-01    0.0243\n",
      "1990-08-01   -0.1222\n",
      "1990-09-01   -0.1082\n",
      "1990-10-01    0.0520\n",
      "1990-11-01   -0.0312\n",
      "Name: SMALL LoBM, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nUsing {portfolio_name} for GARCH modeling. Data shape:\", returns.shape)\n",
    "print(returns.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set period: 1990-07 to 2015-12\n",
      "Testing set period: 2016-01 to 2024-12\n"
     ]
    }
   ],
   "source": [
    "train = returns.loc[:'2015-12-31']\n",
    "test = returns.loc['2016-01-01':]\n",
    "\n",
    "print(\"Training set period:\", train.index.min().strftime('%Y-%m'), \"to\", train.index.max().strftime('%Y-%m'))\n",
    "print(\"Testing set period:\", test.index.min().strftime('%Y-%m'), \"to\", test.index.max().strftime('%Y-%m'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Fit a GARCH(1,1) Model on the Training Set\n",
    "\n",
    "_A GARCH(1,1) model typically suffices for many financial time series, capturing volatility clustering. The `arch` library expects return data (not squared returns), and internally models the variance process._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Zero Mean - GARCH Model Results                        \n",
      "==============================================================================\n",
      "Dep. Variable:             SMALL LoBM   R-squared:                       0.000\n",
      "Mean Model:                 Zero Mean   Adj. R-squared:                  0.003\n",
      "Vol Model:                      GARCH   Log-Likelihood:                474.939\n",
      "Distribution:                  Normal   AIC:                          -943.879\n",
      "Method:            Maximum Likelihood   BIC:                          -932.708\n",
      "                                        No. Observations:                  306\n",
      "Date:                Tue, Feb 18 2025   Df Residuals:                      306\n",
      "Time:                        03:27:30   Df Model:                            0\n",
      "                               Volatility Model                              \n",
      "=============================================================================\n",
      "                 coef    std err          t      P>|t|       95.0% Conf. Int.\n",
      "-----------------------------------------------------------------------------\n",
      "omega      1.5731e-04  1.067e-04      1.475      0.140 [-5.177e-05,3.664e-04]\n",
      "alpha[1]       0.1240  6.227e-02      1.992  4.638e-02    [1.990e-03,  0.246]\n",
      "beta[1]        0.8220  7.899e-02     10.406  2.330e-25      [  0.667,  0.977]\n",
      "=============================================================================\n",
      "\n",
      "Covariance estimator: robust\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GIORDANO\\Desktop\\financial-time-series-forecasting\\env\\Lib\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
      "estimating the model parameters. The scale of y is 0.002983. Parameter\n",
      "estimation work better when this value is between 1 and 1000. The recommended\n",
      "rescaling is 10 * y.\n",
      "\n",
      "This warning can be disabled by either rescaling y before initializing the\n",
      "model or by setting rescale=False.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "garch_model = arch_model(train, p=1, q=1, mean='Zero', vol='GARCH', dist='normal')\n",
    "\n",
    "# Fit the model\n",
    "garch_fit = garch_model.fit(update_freq=5, disp='off')\n",
    "print(garch_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the volatility forecasts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few forecasted variances:\n",
      "date\n",
      "2016-01-01    0.001690\n",
      "2016-02-01    0.001756\n",
      "2016-03-01    0.001818\n",
      "2016-04-01    0.001878\n",
      "2016-05-01    0.001934\n",
      "Name: ForecastedVar, dtype: float64\n",
      "\n",
      "First few forecasted volatilities:\n",
      "date\n",
      "2016-01-01    0.041108\n",
      "2016-02-01    0.041904\n",
      "2016-03-01    0.042643\n",
      "2016-04-01    0.043331\n",
      "2016-05-01    0.043972\n",
      "Name: ForecastedVol, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Number of steps to forecast = length of the test set\n",
    "n_test = len(test)\n",
    "\n",
    "# Forecast the variance over the test horizon\n",
    "garch_forecast = garch_fit.forecast(horizon=n_test, start=train.index[-1], reindex=False)\n",
    "forecasted_variance = garch_forecast.variance.iloc[-1].values # setting 1month horizon\n",
    "pred_variance = pd.Series(forecasted_variance, index=test.index, name='ForecastedVar')\n",
    "\n",
    "# Convert variance to standard deviation\n",
    "pred_volatility = np.sqrt(pred_variance)\n",
    "pred_volatility.name = 'ForecastedVol'\n",
    "\n",
    "print(\"First few forecasted variances:\")\n",
    "print(pred_variance.head())\n",
    "print(\"\\nFirst few forecasted volatilities:\")\n",
    "print(pred_volatility.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing Forecasted Volatility to Realized Volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A common proxy for realized volatility is the squared return (or the absolute return). We'll use squared returns here for consistency with the GARCH variance concept. Then we compute error metrics such as MAE or RMSE between the forecasted standard deviation and the realized standard deviation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            RealizedVol  ForecastedVol\n",
      "date                                  \n",
      "2016-01-01       0.1053       0.041108\n",
      "2016-02-01       0.0051       0.041904\n",
      "2016-03-01       0.0836       0.042643\n",
      "2016-04-01       0.0261       0.043331\n",
      "2016-05-01       0.0160       0.043972\n",
      "\n",
      "Volatility Forecast Error Metrics:\n",
      "MAE: 0.0323\n",
      "RMSE: 0.0378\n"
     ]
    }
   ],
   "source": [
    "# Realized variance ~ squared returns\n",
    "realized_variance = test**2\n",
    "realized_variance.name = 'RealizedVar'\n",
    "realized_vol = np.sqrt(realized_variance)\n",
    "realized_vol.name = 'RealizedVol'\n",
    "\n",
    "# Align forecast and realized series\n",
    "df_compare = pd.concat([realized_vol, pred_volatility], axis=1).dropna()\n",
    "print(df_compare.head())\n",
    "\n",
    "# Compute error metrics (e.g., on volatility, not variance)\n",
    "mae_vol = mean_absolute_error(df_compare['RealizedVol'], df_compare['ForecastedVol'])\n",
    "rmse_vol = np.sqrt(mean_squared_error(df_compare['RealizedVol'], df_compare['ForecastedVol']))\n",
    "\n",
    "print(f\"\\nVolatility Forecast Error Metrics:\\nMAE: {mae_vol:.4f}\\nRMSE: {rmse_vol:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_compare['RealizedVol'], label='Realized Volatility', color='blue')\n",
    "plt.plot(df_compare['ForecastedVol'], label='Forecasted Volatility', color='red', linestyle='--')\n",
    "# add confidence intervals\n",
    "plt.fill_between(df_compare.index, df_compare['ForecastedVol'] - 2*np.sqrt(pred_variance), df_compare['ForecastedVol'] + 2*np.sqrt(pred_variance), color='red', alpha=0.2)\n",
    "plt.title(f'GARCH(1,1) Volatility Forecast for {portfolio_name}')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volatility')\n",
    "plt.legend()\n",
    "plt.savefig('plots/garch_forecast.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will try to achieve major results by using more simulations to forecast volatility \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = len(test)\n",
    "garch_forecast = garch_fit.forecast(\n",
    "    horizon=n_test,\n",
    "    method='simulation',\n",
    "    simulations=1000,  # adjust as needed\n",
    "    reindex=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated variances \n",
    "simulated_variances = garch_forecast.simulations.values\n",
    "mean_simulated_variance = np.mean(simulated_variances, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing confidence intervals by taking percentiles of the simulations.\n",
    "mean_variance = simulated_variances.mean(axis=1)  \n",
    "lower_var_ci = np.percentile(simulated_variances, 2.5, axis=1)\n",
    "upper_var_ci = np.percentile(simulated_variances, 97.5, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GIORDANO\\AppData\\Local\\Temp\\ipykernel_1728\\3726145924.py:1: RuntimeWarning: invalid value encountered in sqrt\n",
      "  mean_vol = np.sqrt(mean_variance)\n",
      "C:\\Users\\GIORDANO\\AppData\\Local\\Temp\\ipykernel_1728\\3726145924.py:2: RuntimeWarning: invalid value encountered in sqrt\n",
      "  lower_vol_ci = np.sqrt(lower_var_ci)\n"
     ]
    }
   ],
   "source": [
    "mean_vol = np.sqrt(mean_variance)\n",
    "lower_vol_ci = np.sqrt(lower_var_ci)\n",
    "upper_vol_ci = np.sqrt(upper_var_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_test = test.index  # or create a date range if needed\n",
    "mean_vol_reshaped = mean_vol.reshape(-1)  # Flatten the array\n",
    "lower_vol_ci_reshaped = lower_vol_ci.reshape(-1)  # Flatten the array\n",
    "upper_vol_ci_reshaped = upper_vol_ci.reshape(-1)  # Flatten the array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realized_vol = np.sqrt(test**2)  # or your chosen realized volatility measure\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(realized_vol, label='Realized Volatility', color='blue')\n",
    "plt.plot(dates_test, mean_vol_reshaped, label='Forecasted Volatility', color='red', linestyle='--')\n",
    "\n",
    "# Filter out nan values for confidence intervals\n",
    "mask = ~np.isnan(upper_vol_ci_reshaped) & ~np.isnan(lower_vol_ci_reshaped)\n",
    "valid_dates = dates_test[mask]\n",
    "valid_upper = upper_vol_ci_reshaped[mask]\n",
    "valid_lower = lower_vol_ci_reshaped[mask]\n",
    "\n",
    "# Fill the CI band with valid values only\n",
    "if len(valid_dates) > 0:  \n",
    "    plt.fill_between(\n",
    "        valid_dates,\n",
    "        valid_lower,\n",
    "        valid_upper,\n",
    "        color='pink',\n",
    "        alpha=0.3,\n",
    "        label='95% Confidence Interval'\n",
    "    )\n",
    "\n",
    "plt.title('GARCH(1,1) Volatility Forecast for SMALL LoBM with Confidence Intervals')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volatility')\n",
    "plt.legend()\n",
    "plt.savefig('plots/garch_forecast_confidence_intervals.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
